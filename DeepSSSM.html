<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Seeing Beyond Vision | Deep SSSM</title>

<!-- MathJax -->
<script type="text/javascript" async
  src="https://cdn.jsdelivr.net/npm/mathjax@2/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
<!-- End MathJax -->

</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">

  <!-- Left navigation -->
  <td id="layout-menu">
    <div class="menu-category">Thanana</div>
    <div class="menu-item"><a href="index.html">Home</a></div>
    <div class="menu-item"><a href="Biography.html">Biography</a></div>
    <div class="menu-item"><a href="Publication.html">Publication</a></div>

    <div class="menu-category">Research</div>
    <div class="menu-item"><a href="tactile_intelligence.html">Tactile&nbsp;Intelligence</a></div>
    <div class="menu-item"><a href="DeepSSSM.html" class="current">Seeing&nbsp;Beyond&nbsp;Vision</a></div>
    <div class="menu-item"><a href="nonholonomic.html">Holonomic&nbsp;Systems</a></div>
    <div class="menu-item"><a href="Cyber.html">Data-driven&nbsp;Control</a></div>
    <div class="menu-item"><a href="large-scale.html">Large-scale&nbsp;System</a></div>

    <div class="menu-category">Teaching</div>
    <div class="menu-item"><a href="reinforcement_learning.html">Reinforcement&nbsp;Learning</a></div>

    <div class="menu-category">Software</div>
    <div class="menu-item"><a href="robotics.html">Robotics</a></div>
    <div class="menu-item"><a href="image.html">Image&nbsp;Processing</a></div>
  </td>

  <!-- Main content -->
  <td id="layout-content">
  <div id="toptitle">
    <h1>Seeing Beyond Vision</h1>
    <p style="font-size:1.05em; color:#555; margin-top:-10px;">
      <i>(Deep Stochastic State-Space Models)</i>
    </p>
  </div>

  <!-- Motto block -->
  <div style="text-align:center; margin:20px auto; max-width:700px; line-height:1.5;">
    <p style="color:#00A6D6; font-style:italic; font-size:1.1em; margin-bottom:6px;">
      “To see beyond vision — robots that imagine what they cannot see.”
    </p>
    <p style="color:#003366; font-size:0.95em; font-style:italic; margin-top:0;">
      <b>Challenge</b> uncertainty,&nbsp;
      <b>Change</b> perception through latent dynamics,&nbsp;
      and drive <b>Impact</b> toward uncertainty-aware embodied intelligence.
    </p>
  </div>

  <hr style="border:0; border-top:1px solid #ccc; width:50%; margin:16px auto;">

  <h2>Deep Stochastic State-Space Models (Deep SSSM)</h2>

  <!-- Main figure -->
  <div style="text-align:center; margin-top:10px; margin-bottom:5px;">
    <img src="DeepSSSM1.pdf" alt="Deep SSSM framework" width="420"
         style="margin-bottom:10px; border-radius:4px;">
  </div>

  <!-- Pipeline below figure -->
  <div style="text-align:center; margin-top:4px; margin-bottom:20px;">
    <p style="color:#003366; font-style:italic; font-size:0.9em;">
      Deep SSSM pipeline: <b>Observation</b> → <b>Latent State Inference</b> → 
      <b>Stochastic Prediction</b> → <b>Control &amp; Planning</b> → <b>Feedback</b>
    </p>
  </div>

  <!-- Optional light blue loop banner -->
  <div style="text-align:center; background-color:#f8f9fb; border-radius:10px; padding:12px 10px; margin:10px auto 25px auto; max-width:720px; box-shadow:0 0 3px rgba(0,0,0,0.08);">
    <p style="margin:0; font-size:0.95em; color:#003366;">
      <span style="color:#00A6D6;"><b>Perception</b></span> → 
      <span style="color:#006699;"><b>Inference</b></span> → 
      <span style="color:#0099CC;"><b>Prediction</b></span> → 
      <span style="color:#00A6D6;"><b>Planning</b></span> → 
      <span style="color:#003366;"><b>Action</b></span>
    </p>
    <p style="margin:4px 0 0 0; font-size:0.85em; color:#666;">
      (Robots learn to act beyond direct observation through stochastic world modeling)
    </p>
  </div>

  <!-- Explanatory text -->
  <p>
    Deep SSSMs are <strong>probabilistic world models</strong> that combine 
    <em>stochastic latent dynamics</em> with <em>control-theoretic planning</em>. 
    They enable robots to reason about hidden or occluded states, predict the 
    evolution of the environment, and plan actions under uncertainty.
  </p>

  <h2>What Is Deep SSSM?</h2>
  <p>
    A Deep Stochastic State-Space Model learns to represent complex, partially observable
    systems as <strong>latent state variables</strong> governed by probabilistic transitions:
  </p>

  <p style="text-align:center;">
    \[
    s_{t+1} \sim p(s_{t+1}\mid s_t, a_t), \quad o_t \sim p(o_t \mid s_t)
    \]
  </p>

  <p>
    This latent formulation allows the model to predict how the system evolves while
    maintaining uncertainty over unobserved variables.
  </p>

  <h2>Key Challenges</h2>
  <p>
    Real-world robotic environments are often <em>occluded, noisy, or incomplete</em>.
    Conventional deterministic world models fail in these conditions, producing 
    overconfident predictions that degrade control performance.
    The challenge is to represent <strong>uncertainty explicitly</strong> while retaining
    computational tractability for real-time decision-making.
  </p>

  <h2>How Deep SSSM Addresses This</h2>
  <p>
    Deep SSSM learns a <strong>stochastic latent representation</strong> that encodes both 
    dynamics and uncertainty. Instead of predicting single trajectories, it models
    <em>distributions over future states</em>. This probabilistic approach enables
    uncertainty-aware control policies that remain stable even under occlusion or 
    unseen disturbances.
  </p>

  <h2>Impact and Applications</h2>
  <p>
    Deep SSSM provides a foundation for <strong>occlusion-robust visual control</strong> and 
    <strong>uncertainty-aware decision-making</strong> in robotics. 
    It has broad implications for:
  </p>
  <ul>
    <li>Vision-based manipulation under partial observability</li>
    <li>Human–robot collaboration and shared autonomy</li>
    <li>Predictive control under dynamic, uncertain conditions</li>
  </ul>

  <p style="font-size:0.85em; color:#777; text-align:center;">
    <i>Toward robots that reason in uncertainty — perceiving, predicting, and acting beyond what is seen.</i>
  </p>

  <!-- Footer -->
  <div id="footer">
    <div id="footer-text" style="font-size:0.85em; color:#777;">
      © 2025 Thanana Nuchkrua | Control & Robotics Research Group
    </div>
  </div>

  </td>
</tr>
</table>
</body>
</html>
